{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part B (Neural Network as Logic Gates)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import math\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Class Definition</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1682,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    \n",
    "    # When we initialize a neural network the only information that we give it \n",
    "    # will be a list of the size of each layer in the network.\n",
    "    def __init__(self, layer_sizes):\n",
    "        \n",
    "        # Get the number of layers that the user wants the network to contain.\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.num_layers = len(self.layer_sizes)\n",
    "        \n",
    "        # Build the weights for our network.\n",
    "        # The layout for the weights will be a list of matrices for now.\n",
    "        # The shape of a given weight item in the list will be [from layer size + 1, to layer size]\n",
    "        # We add the plus 1 in the from size to account for the bias neuron of that layer.\n",
    "        self.thetas = [0 for x in range(0,len(layer_sizes)-1)]\n",
    "            \n",
    "    # For the NeuralNetwork class getLayer() just sends the caller the list of weights\n",
    "    # for the entire network.\n",
    "    def getLayer(self, layer):\n",
    "        return self.thetas[layer]\n",
    "        \n",
    "    # Where the magic happens for this class. When the user calls the forward method \n",
    "    # for a NeuralNetwork object with an input list of integers, we feed those\n",
    "    # integers into the network, multiplying by each weight matrix.\n",
    "    def forward(self, input_list):\n",
    "\n",
    "        # Initialize a list of all of the weighted sums that we will get from \n",
    "        # multiplying a previous layer by the connection weights.\n",
    "        z = []\n",
    "        \n",
    "        # Initialize a list of all of the sigmoid nonlinearity results\n",
    "        # This will end up being the same size as the weighted sums (z)\n",
    "        a = []\n",
    "        \n",
    "        # This is just a PyTorch tensor created from the users' input and \n",
    "        # reshaped to be a horizontal row of inputs.\n",
    "        first_layer_no_bias = torch.FloatTensor(input_list).view(1, len(input_list))\n",
    "        \n",
    "        # Add our first z values which will be the input layer. Since there is no nonlinearity\n",
    "        # applied to the input before sending it into the network, we just set the first\n",
    "        # a value to be the input array as well.\n",
    "        z.append(first_layer_no_bias)\n",
    "        a.append(z[0])\n",
    "                    \n",
    "        # Iterate through each layer of the matrix until 1 before the output layer.\n",
    "        for i in range(0,self.num_layers-1):\n",
    "            \n",
    "            # Create a PyTorch tensor with a single value and then concatenate it \n",
    "            # onto the front of the input array. This is our bias value and when \n",
    "            # concatenated it creates our input along with the bias. \n",
    "            # We add a bias item to every layer within this loop\n",
    "            bias = torch.ones(1, 1)\n",
    "            layer_with_bias = torch.cat([bias, a[i]], 1)\n",
    "            \n",
    "            # Create the input to our sigmoid nonlinearity by matrix multiplying \n",
    "            # the current layer that we're on with the appropriate weight matrix.\n",
    "            z.append(torch.mm(layer_with_bias, self.thetas[i]))\n",
    "            a.append(1/(1+np.exp(-z[-1])))\n",
    "            \n",
    "\n",
    "        # This is a bit of a bug, I'm getting outputs that are not in fact shaped according \n",
    "        # to any laws of linear algebra. For now just taking the first element of the very last\n",
    "        # a value has been doing just fine. \n",
    "        result = a[-1][0][0]\n",
    "        \n",
    "        # If binary output desired:\n",
    "        if result >= 0.5:\n",
    "            result = 1.0\n",
    "        elif result < 0.5:\n",
    "            result = 0.0\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Logic Gate Class Definition</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1683,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AND():\n",
    "    def __init__(self):\n",
    "        layer_sizes = [2, 1]\n",
    "        self.network = NeuralNetwork(layer_sizes)\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        self.x = int(x)\n",
    "        self.y = int(y)\n",
    "        return self.forward()\n",
    "    \n",
    "    def getLayer(self, theta, layer):\n",
    "        self.network.thetas[layer] = theta\n",
    "        \n",
    "    def forward(self):\n",
    "        input_array = [self.x, self.y]\n",
    "        result = self.network.forward(input_array)\n",
    "        \n",
    "        return bool(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1684,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OR():\n",
    "    def __init__(self):       \n",
    "        layer_sizes = [2, 1]\n",
    "        self.network = NeuralNetwork(layer_sizes)\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        self.x = int(x)\n",
    "        self.y = int(y)\n",
    "        return self.forward()\n",
    "    \n",
    "    def getLayer(self, theta, layer):\n",
    "        self.network.thetas[layer] = theta\n",
    "        \n",
    "    def forward(self):\n",
    "        input_array = [self.x, self.y]\n",
    "        result = self.network.forward(input_array)\n",
    "        \n",
    "        return bool(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NOT():\n",
    "    def __init__(self):\n",
    "        layer_sizes = [2, 1]\n",
    "        self.network = NeuralNetwork(layer_sizes)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        self.x = int(x)\n",
    "        return self.forward()\n",
    "    \n",
    "    def getLayer(self, theta, layer):\n",
    "        self.network.thetas[layer] = theta\n",
    "        \n",
    "    def forward(self):\n",
    "        input_array = [self.x]\n",
    "        result = self.network.forward(input_array)\n",
    "        \n",
    "        return bool(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XOR():\n",
    "    def __init__(self):\n",
    "        layer_sizes = [2, 2, 1]\n",
    "        self.network = NeuralNetwork(layer_sizes)\n",
    "\n",
    "    def __call__(self, x, y):\n",
    "        self.x = int(x)\n",
    "        self.y = int(y)\n",
    "        return self.forward()\n",
    "    \n",
    "    def getLayer(self, theta, layer):\n",
    "        self.network.thetas[layer] = theta\n",
    "        \n",
    "    def forward(self):\n",
    "        input_array = [self.x, self.y]\n",
    "        result = self.network.forward(input_array)\n",
    "        \n",
    "        return bool(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Class Instantiation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND result:  True\n",
      "OR result:  True\n",
      "NOT result:  True\n",
      "XOR result:  False\n"
     ]
    }
   ],
   "source": [
    "And = AND()\n",
    "Or = OR()\n",
    "Not = NOT()\n",
    "Xor = XOR()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Weight Definitions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>AND Weights</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "and_thetas = [torch.tensor([\n",
    "    [-2.0], \n",
    "    [ 1.5], \n",
    "    [ 1.5]\n",
    "]).float()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>OR Weights</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "or_thetas = [torch.tensor([\n",
    "    [-0.25], \n",
    "    [ 1.5], \n",
    "    [ 1.5]\n",
    "]).float()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>AND Weights</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_thetas = [torch.tensor([\n",
    "    [ 0.0],\n",
    "    [-1.0]\n",
    "]).float()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>XOR Weights</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xor_thetas = [torch.tensor([\n",
    "    [-0.25, 2.0],\n",
    "    [ 1.5, -1.5],\n",
    "    [ 1.5, -1.5]\n",
    "]).float(), torch.tensor([\n",
    "    [-2.0],\n",
    "    [ 1.5],\n",
    "    [ 1.5]\n",
    "]).float()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>getLayer() Method Testing/Set Weights<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "And.getLayer(and_thetas[0], 0)\n",
    "Or.getLayer(or_thetas[0], 0)\n",
    "Not.getLayer(not_thetas[0], 0)\n",
    "Xor.getLayer(xor_thetas[0], 0)\n",
    "Xor.getLayer(xor_thetas[1], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Testing The Logic Gates</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AND result: \", And(True, True))\n",
    "print(\"OR result: \", Or(False, True))\n",
    "print(\"NOT result: \", Not(False)) \n",
    "print(\"XOR result: \", Xor(False, False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
